{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow_io as tfio\n",
    "os.chdir(r'C:\\Users\\HH\\Desktop\\project')\n",
    "import Language_Model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c57ddfb93a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mFeed_forward_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mencoder_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class Feed_forward_module(keras.Model):\n",
    "    def __init__(self,encoder_width,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1=keras.layers.LayerNormalization(axis=1)\n",
    "        self.hidden2=keras.layers.Dense(4*encoder_width)\n",
    "        self.hidden3=keras.activations.swish\n",
    "        self.hidden4=keras.layers.Dropout(0.1)\n",
    "        self.hidden5=keras.layers.Dense(encoder_width)\n",
    "        self.hidden6=keras.layers.Dropout(0.1)\n",
    "        self.hidden7=keras.layers.Add()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x=self.hidden1(inputs)\n",
    "#         print('ff layer normalization')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden2(x)\n",
    "#         print('ff dense layer')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden3(x)\n",
    "#         print('ff swish activation')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden4(x)\n",
    "#         print('ff drop out')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden5(x)\n",
    "#         print('ff dense')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden6(x)\n",
    "        x=0.5*x\n",
    "#         print('ff drop out')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden7([x,inputs])\n",
    "#         print('ff add')\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_module(keras.Model):\n",
    "    def __init__(self,encoder_width,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1=keras.layers.LayerNormalization(axis=1)\n",
    "        self.hidden2=keras.layers.Conv1D(filters=1,kernel_size=1,input_shape=(encoder_width,1))\n",
    "        #GLU activation\n",
    "        #self.hidden4=keras.layers.Conv1D(filters=2,kernel_size=32,padding='same',groups=2)\n",
    "        self.hidden5=keras.layers.BatchNormalization()\n",
    "        self.hidden6=keras.activations.swish\n",
    "        self.hidden7=keras.layers.Conv1D(1,1)\n",
    "        self.hidden8=keras.layers.Dropout(0.1)\n",
    "        self.hidden9=keras.layers.Add()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        inputs=tf.expand_dims(inputs,axis=-1)\n",
    "        x=self.hidden1(inputs)\n",
    "#         print('conv layernorm')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden2(x)\n",
    "#         print('conv pointwise')\n",
    "#         print(x.shape)\n",
    "        #x=self.hidden3(x)\n",
    "        #x=self.hidden4(x)\n",
    "        #print('conv separableconv1d')\n",
    "        #print(x.shape)\n",
    "        x=self.hidden5(x)\n",
    "#         print('conv batchnormalization')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden6(x)\n",
    "#         print('conv swish activation')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden7(x)\n",
    "#         print('conv pointwise')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden8(x)\n",
    "#         print('conv dropout')\n",
    "#         print(x.shape)\n",
    "        x=self.hidden9([x,inputs])\n",
    "#         print('conv add')\n",
    "#         print(x.shape)\n",
    "        x=tf.squeeze(x,axis=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Multi_Head_Attention(keras.Model):\n",
    "    #def __init__(self,head_size,num_heads,**kwargs):\n",
    "        #super().__init__(**kwargs)\n",
    "        #self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multihead_module(keras.Model):\n",
    "    def __init__(self,head_size,num_heads,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layernorm=keras.layers.LayerNormalization(axis=1)\n",
    "        self.multihead=tfa.layers.MultiHeadAttention(head_size,num_heads)\n",
    "        self.dropout=keras.layers.Dropout(0.1)\n",
    "        self.add=keras.layers.Add()\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        positional_embedding=np.array([math.sin(i/144) for i in range(144)])[np.newaxis,:]\n",
    "        x=inputs+positional_embedding\n",
    "        x=self.layernorm(x)\n",
    "#         print('multihead layernorm')\n",
    "#         print(x.shape)\n",
    "        x=self.multihead([x,x,x])\n",
    "#         print('multihead multihead')\n",
    "#         print(x.shape)\n",
    "        x=self.dropout(x)\n",
    "#         print('multihead drop out')\n",
    "#         print(x.shape)\n",
    "        x=self.add([x,inputs])\n",
    "#         print('multihead add')\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conformer_block(keras.Model):\n",
    "    def __init__(self,head_size,num_heads,encoder_width,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.ff1=Feed_forward_module(encoder_width)\n",
    "        self.multihead=Multihead_module(head_size,num_heads)\n",
    "        self.conv=Conv_module(encoder_width)\n",
    "        self.ff2=Feed_forward_module(encoder_width)        \n",
    "    def call(self,inputs):\n",
    "        x=self.ff1(inputs)\n",
    "#         print('conformer feedforward1')\n",
    "#         print(x.shape)\n",
    "        x=self.multihead(x)\n",
    "#         print('conformer multihead')\n",
    "#         print(x.shape)\n",
    "        x=self.conv(x)\n",
    "#         print('conformer convolution')\n",
    "#         print(x.shape)\n",
    "        x=self.ff2(x)\n",
    "#         print('conformer feedforward2')\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self,num_conformers,head_size,num_heads,encoder_width,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1=keras.layers.Conv2D(1,(2,2),strides=2,input_shape=(111,2975,80,1))\n",
    "        self.relu1=keras.activations.relu\n",
    "        self.conv2=keras.layers.Conv2D(1,(2,2),strides=2)\n",
    "        self.relu2=keras.activations.relu\n",
    "        self.flat=keras.layers.Flatten()\n",
    "        self.linear=keras.layers.Dense(encoder_width)\n",
    "        self.dropout=keras.layers.Dropout(0.1)\n",
    "        self.conformers=[Conformer_block(head_size,num_heads,encoder_width) for i in range(num_conformers)]\n",
    "    def call(self,inputs,training):\n",
    "        x=self.conv1(inputs)\n",
    "#         print('conformer_encoder 2D convolution')\n",
    "#         print(x.shape)\n",
    "        x=self.relu1(x)\n",
    "#         print('conformer_encoder relu activation')\n",
    "#         print(x.shape)\n",
    "        x=self.conv2(x)\n",
    "#         print('conformer_encoder 2D convolution')\n",
    "#         print(x.shape)\n",
    "        x=self.relu2(x)\n",
    "#         print('conformer_encoder relu activation')\n",
    "#         print(x.shape)\n",
    "        x=self.flat(x)\n",
    "#         print('conformer_encoder flatten')\n",
    "#         print(x.shape)\n",
    "        x=self.linear(x)\n",
    "#         print('conformer_encoder dense')\n",
    "#         print(x.shape)\n",
    "        x=self.dropout(x)\n",
    "#         print('conformer_encoder drop out')\n",
    "#         print(x.shape)\n",
    "        for layer in self.conformers:\n",
    "            x=layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-685498cccdb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedding_num_dimensions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSOS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEOS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membbeding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedding_num_dimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self,vocab_size,decoder_width,max_len,embedding_num_dimensions,SOS=1,EOS=2,**kwargs):\n",
    "        super(). __init__(**kwargs)\n",
    "        self.embbeding = keras.layers.Embedding(vocab_size,embedding_num_dimensions)\n",
    "        self.lstm = keras.layers.LSTM(decoder_width,return_sequences=True,return_state=True,dropout=0.1)\n",
    "        self.dense = keras.layers.Dense(vocab_size,activation='softmax')\n",
    "        self.SOS = SOS\n",
    "        self.EOS = EOS\n",
    "        self.max_len = max_len\n",
    "        self.vocab_size = vocab_size\n",
    "#         self.lamda = lamda\n",
    "#         self.LM = LM\n",
    "\n",
    "    def call(self,inputs,training=True):\n",
    "        if training:\n",
    "            x = self.embbeding(inputs[1])\n",
    "            x,_,__ = self.lstm(x,initial_state=[inputs[0], inputs[0]])\n",
    "            x = self.dense(x)\n",
    "            return x\n",
    "        else:\n",
    "            current_subword = self.SOS\n",
    "            h,c = inputs,inputs\n",
    "            outputs = []\n",
    "            for i in range(self.max_len):\n",
    "                if current_subword == self.EOS:\n",
    "                    break\n",
    "                x = self.embbeding(current_subword)[np.newaxis,np.newaxis,:]\n",
    "                x,h,c = self.lstm(x,initial_state=[h,c])\n",
    "                x = self.dense(x).numpy()\n",
    "                x=np.squeeze(x,axis=0)\n",
    "                #print('the shape of x is ',x.shape)\n",
    "#                 if i == 0:\n",
    "#                     print('the shape is',np.array(self.LM.predict(np.array([self.SOS])[np.newaxis,:])).shape)\n",
    "#                     y = np.array(self.LM.predict(np.array([self.SOS])[np.newaxis,:]))#np.squeeze(x,axis=0)\n",
    "#                 else:\n",
    "#                     print('the shape of outputs is',np.array(outputs).shape)\n",
    "#                     y=np.array(self.LM.predict(np.expand_dims(np.array(outputs),axis=0)))\n",
    "#                     print('the shape of y1 is ',y.shape)\n",
    "# #                     y=np.squeeze(y,axis=0)\n",
    "# #                     print('the shape of y2 is',y.shape)\n",
    "#                 current_subword = int(np.argmax(x*self.lamda+y*(1-self.lamda)))\n",
    "                current_subword= int(np.argmax(x))\n",
    "                outputs.append(current_subword)\n",
    "            return np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b469910d7a3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mConformer_transducer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_conformers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhead_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m144\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m977\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m144\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedding_num_dimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSOS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEOS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class Conformer_transducer(keras.Model):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = Encoder(num_conformers=16,head_size=16,num_heads=4,encoder_width=144)\n",
    "        self.decoder = Decoder(vocab_size=977,decoder_width=144,max_len=90,embedding_num_dimensions=320,SOS=1,EOS=2)\n",
    "        #self.wpm = Language_Model.WPM(vocab_source=r'C:\\Users\\HH\\Desktop\\project\\newvocab2.txt')\n",
    "    def call(self,inputs,training):\n",
    "        if training:\n",
    "            x = self.encoder(inputs[0])\n",
    "            x = self.decoder([x,inputs[1]],training=True)\n",
    "        else:\n",
    "            x = self.encoder(inputs)\n",
    "            x = self.decoder(x)\n",
    "            #x = self.wpm.getWords(x)\n",
    "        return x\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
